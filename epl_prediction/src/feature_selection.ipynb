{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/extracted_features_dataset.csv')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_normalise = data.columns.difference(['Season', 'HomeTeam', 'AwayTeam', 'FTR'])\n",
    "\n",
    "data[columns_to_normalise] = data[columns_to_normalise].apply(lambda x: (x - x.mean()) / x.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(['FTR', 'Season', 'HomeTeam', 'AwayTeam'], axis=1)\n",
    "y = data['FTR']\n",
    "\n",
    "le = LabelEncoder()\n",
    "y_encoded = le.fit_transform(y)\n",
    "\n",
    "print(\"Target variable encoding:\")\n",
    "for i, category in enumerate(le.classes_):\n",
    "    print(f\"{category}: {i}\")\n",
    "\n",
    "#Correlation analysis\n",
    "correlation_matrix = X.corr()\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(20, 16))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated features\n",
    "threshold = 0.8\n",
    "high_corr_features = np.where(np.abs(correlation_matrix) > threshold)\n",
    "high_corr_features = [(correlation_matrix.index[x], correlation_matrix.columns[y]) \n",
    "                      for x, y in zip(*high_corr_features) if x != y and x < y]\n",
    "\n",
    "print(\"Highly correlated feature pairs:\")\n",
    "for feat1, feat2 in high_corr_features:\n",
    "    print(f\"{feat1} and {feat2}: {correlation_matrix.loc[feat1, feat2]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is far too many features to get any useful information from this..., lets try a basic model to extract useful features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature importance using Random Forest\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X, y_encoded)\n",
    "\n",
    "feature_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': rf_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most important features:\")\n",
    "print(feature_importance.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort features by importance\n",
    "feature_importance = feature_importance.sort_values('importance', ascending=False)\n",
    "\n",
    "# Calculate cumulative importance\n",
    "feature_importance['cumulative_importance'] = feature_importance['importance'].cumsum()\n",
    "\n",
    "print(\"Top 10 features by importance:\")\n",
    "print(feature_importance.head(10))\n",
    "\n",
    "# Find number of features for 80% cumulative importance\n",
    "features_for_80 = feature_importance[feature_importance['cumulative_importance'] <= 0.8].shape[0]\n",
    "print(f\"\\nNumber of features accounting for 80% of importance: {features_for_80}\")\n",
    "\n",
    "# Identify features above 1% importance\n",
    "important_features = feature_importance[feature_importance['importance'] > 0.01]\n",
    "print(f\"\\nNumber of features with >1% importance: {important_features.shape[0]}\")\n",
    "print(\"These features are:\")\n",
    "print(important_features['feature'].tolist())\n",
    "\n",
    "# Visualize feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importance.head(20))\n",
    "plt.title('Top 20 Most Important Features')\n",
    "plt.show()\n",
    "\n",
    "# Visualize cumulative importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, len(feature_importance) + 1), feature_importance['cumulative_importance'])\n",
    "plt.xlabel('Number of Features')\n",
    "plt.ylabel('Cumulative Importance')\n",
    "plt.title('Cumulative Feature Importance')\n",
    "plt.axhline(y=0.8, color='r', linestyle='--')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key_words = [\n",
    "    'PointsPG',\n",
    "    'GoalDifferencePG',\n",
    "    'GoalsScoredPG',\n",
    "    'GoalsConcededPG',\n",
    "    'ShotsPG',\n",
    "    'FoulsPG',\n",
    "    'CornersPG',\n",
    "    'YellowCardsPG',\n",
    "    'RedCardsPG',\n",
    "    'FinishingPosition'\n",
    "]\n",
    "\n",
    "key_word_importances_seasonal = {}\n",
    "key_word_importances_opponent = {}\n",
    "for word in key_words:\n",
    "    importances_seasonal = feature_importance[feature_importance['feature'].str.contains(word) & ~(feature_importance['feature'].str.contains('Opponent'))]\n",
    "    key_word_importance_seasonal = importances_seasonal['importance'].abs().sum()\n",
    "    key_word_importances_seasonal[word + 'Seasonal'] = key_word_importance_seasonal\n",
    "\n",
    "    importances_opponent = feature_importance[feature_importance['feature'].str.contains(word) & (feature_importance['feature'].str.contains('Opponent'))]\n",
    "    key_word_importance_opponent = importances_opponent['importance'].abs().sum()\n",
    "    key_word_importances_opponent[word + 'Opponent'] = key_word_importance_opponent\n",
    "\n",
    "# Convert the dictionary to a pandas Series and sort\n",
    "sorted_importances_seasonal = pd.Series(key_word_importances_seasonal).sort_values(ascending=False)\n",
    "sorted_importances_opponent = pd.Series(key_word_importances_opponent).sort_values(ascending=False)\n",
    "\n",
    "# Print the sorted Series\n",
    "print(sorted_importances_seasonal)\n",
    "print(\"\\n\\n\")\n",
    "print(sorted_importances_opponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to note:\n",
    "- Seasonal features are more important than opponent features.\n",
    "---\n",
    "- GoalDifference is the most important seasonal feature, followed by shots and then points.\n",
    "- Corners are suprisingly important, though maybe its more representative of shots being important than anything, as more shots often lead to more corners.\n",
    "- Suprisingly, goals conceded is of somewhat little importance (when compared to other seasonal features). Considering the phrase \"goals win games, defence wins championships\", this is quite suprising, I would have expected it to be more important.\n",
    "  - That being said, as per my original thought, it seems goal difference could act for both goals scored and goals conceded. Does this mean its importance is being overestimated? or the others are being redundant.\n",
    "- As I thought may be the case, fouls, yellow and red cards are not very important. This is probably because they are more representative of a team's style of play rather than being indicative of a team's performance, and tactical fouling is a thing...\n",
    "---\n",
    "- Against opponent features, the most important ones are shots and fouls, followed by corners and yellow cards.\n",
    "- Interestingly, with the exception of shots, this is completely different to seasonal features.\n",
    "  - Wondering if this suggests that style of play is more important than general team quality when it comes to head-to-head results.\n",
    "\n",
    "- Finishing position has no importance at all?? This is probably an error in my code.\n",
    "  - Need to check this.\n",
    "  - note - 0 importance features against opponent are just because they are not being calculated for the opponent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Assuming X is your feature matrix and y is your target variable\n",
    "n_splits = 5\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "feature_importance_scores = np.zeros(X.shape[1])\n",
    "feature_selection_frequency = np.zeros(X.shape[1])\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    # Perform feature selection\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    selector = SelectFromModel(rf, prefit=False)\n",
    "    rf.fit(X_train, y_train)\n",
    "    selector.fit(X_train, y_train)\n",
    "    \n",
    "    # Record which features were selected\n",
    "    feature_selection_frequency += selector.get_support()\n",
    "    \n",
    "    # Record feature importance scores\n",
    "    feature_importance_scores += rf.feature_importances_\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize a list to store accuracy scores\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, val_index in kf.split(X):\n",
    "    X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "    y_train, y_val = y_encoded[train_index], y_encoded[val_index]\n",
    "    \n",
    "    # Train the model\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    rf.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions\n",
    "    y_pred = rf.predict(X_val)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_val, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "\n",
    "# Calculate the average accuracy\n",
    "average_accuracy = np.mean(accuracy_scores)\n",
    "print(f\"Average accuracy over {n_splits} folds: {average_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "# Average the scores and frequencies\n",
    "feature_importance_scores /= n_splits\n",
    "feature_selection_frequency /= n_splits\n",
    "\n",
    "# Create a DataFrame with the results\n",
    "feature_selection_results = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': feature_importance_scores,\n",
    "    'selection_frequency': feature_selection_frequency\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 features by cross-validated importance:\")\n",
    "print(feature_selection_results.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature elimination\n",
    "\n",
    "We are going to eliminate features that are not important both in terms of results and intuition.\n",
    "\n",
    "- seasonal:\n",
    "  - Yellow and red cards are not super important.\n",
    "  - Fouls are not very important.\n",
    "  - While goals conceded is supposedly not super important, I think this is moreso down to the results provided by rf.feature_importance, I am going to veto this and keep it in for now.\n",
    "  - Later I also want to experiment with no goal difference, and just use goals scored and conceded.\n",
    "- Opponent:\n",
    "  - red and yellow cards are not super important\n",
    "  - nor is points (although i guess goals/shots can represent this fairly well)\n",
    "  - I am going to veto this and keep points in for now though."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_30_most_important_features = data[['HomeTeam', 'AwayTeam', 'FTR'] + feature_selection_results['feature'].tolist()[:30]]\n",
    "data_with_30_most_important_features = pd.get_dummies(data_with_30_most_important_features, columns=['HomeTeam', 'AwayTeam'])\n",
    "data_with_30_most_important_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on a mixture of feature importance and intuition:\n",
    "data_with_removals = data.drop(columns=[\n",
    "    'HomeTeamYellowCardsPGAtHome',\n",
    "    'HomeTeamYellowCardsPGOverall',\n",
    "    'AwayTeamYellowCardsPGOnAway',\n",
    "    'AwayTeamYellowCardsPGOverall',\n",
    "    'HomeTeamRedCardsPGAtHome',\n",
    "    'HomeTeamRedCardsPGOverall',\n",
    "    'AwayTeamRedCardsPGOnAway',\n",
    "    'AwayTeamRedCardsPGOverall',\n",
    "    'HomeTeamFoulsPGAtHome',\n",
    "    'HomeTeamFoulsPGOverall',\n",
    "    'AwayTeamFoulsPGOnAway',\n",
    "    'AwayTeamFoulsPGOverall',\n",
    "\n",
    "    'HomeTeamYellowCardsPGAtHomeAgainstOpponent',\n",
    "    'HomeTeamYellowCardsPGOverallAgainstOpponent',\n",
    "    'AwayTeamYellowCardsPGOnAwayAgainstOpponent',\n",
    "    'AwayTeamYellowCardsPGOverallAgainstOpponent',\n",
    "])\n",
    "data_with_removals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_seasonal_features_only = data_with_removals.loc[:, ~data_with_removals.columns.str.contains('Opponent')].drop(columns=['Season'])\n",
    "data_with_seasonal_features_only = pd.get_dummies(data_with_seasonal_features_only, columns=['HomeTeam', 'AwayTeam'])\n",
    "data_with_seasonal_features_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_minus_gd = data_with_removals.drop(columns=data_with_removals.columns[data_with_removals.columns.str.contains('GoalDifferencePG')].tolist() + ['Season'])\n",
    "data_minus_gd = pd.get_dummies(data_minus_gd, columns=['HomeTeam', 'AwayTeam'])\n",
    "data_minus_gd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "promoted_teams = pd.read_csv(\"../data/promoted_teams.csv\")\n",
    "\n",
    "data_without_promoted_teams = data_with_removals[~data_with_removals.apply(lambda row: (row['HomeTeam'] in promoted_teams['Team'].values and row['Season'] in promoted_teams[promoted_teams['Team'] == row['HomeTeam']]['Season'].values) or (row['AwayTeam'] in promoted_teams['Team'].values and row['Season'] in promoted_teams[promoted_teams['Team'] == row['AwayTeam']]['Season'].values), axis=1)]\n",
    "data_without_promoted_teams = pd.get_dummies(data_without_promoted_teams, columns=['HomeTeam', 'AwayTeam']).drop(columns=['Season'])\n",
    "data_without_promoted_teams.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_removals_encoded = pd.get_dummies(data_with_removals, columns=['HomeTeam', 'AwayTeam']).drop(columns=['Season'])\n",
    "data_with_removals_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_30_most_important_features.to_csv('../preprocessed_data/data_with_30_most_important_features.csv', index=False)\n",
    "data_with_seasonal_features_only.to_csv('../preprocessed_data/data_with_seasonal_features_only.csv', index=False)\n",
    "data_minus_gd.to_csv('../preprocessed_data/data_minus_gd.csv', index=False)\n",
    "data_without_promoted_teams.to_csv('../preprocessed_data/data_without_promoted_teams.csv', index=False)\n",
    "data_with_removals_encoded.to_csv('../preprocessed_data/data_with_removals_encoded.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "epl-prediction-fZ7oNFll-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
